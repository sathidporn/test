{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.8 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "c63538bcf0f881eedb906fa1fb05626f7592ba7487f46e560ce7b80fbd7ebaa7"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ibm-cos-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to Cloud Object Storage\n",
    "import ibm_boto3\n",
    "from ibm_botocore.client import Config, ClientError\n",
    "\n",
    "# Constants for IBM COS values\n",
    "COS_ENDPOINT = \"https://s3.us-south.cloud-object-storage.appdomain.cloud\" # Current list avaiable at https://control.cloud-object-storage.cloud.ibm.com/v2/endpoints\n",
    "\n",
    "COS_API_KEY_ID = \"w9OYjZ0qricse-Z0Sar08ccWq6XQw_3HmG4uUzA6qXwm\" # eg \"W00YixxxxxxxxxxMB-odB-2ySfTrFBIQQWanc--P3byk\"\n",
    "\n",
    "COS_INSTANCE_CRN = \"crn:v1:bluemix:public:cloud-object-storage:global:a/a2fbcfc73145484da67dd67dbc4f914d:c9ef8a5f-f92d-4fd7-a5a8-8cb94bb46b28::\" # eg \"crn:v1:bluemix:public:cloud-object-storage:global:a/3bf0d9003xxxxxxxxxx1c3e97696b71c:d6f04d83-6c4f-4a62-a165-696756d63903::\"\n",
    "\n",
    "# Create client \n",
    "cos = ibm_boto3.client(\"s3\",\n",
    "    ibm_api_key_id=COS_API_KEY_ID,\n",
    "    ibm_service_instance_id=COS_INSTANCE_CRN,\n",
    "    config=Config(signature_version=\"oauth\"),\n",
    "    endpoint_url=COS_ENDPOINT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "package.info(), component.info(), mastertable.info(), model.info(), derive.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(cos.get_object(Bucket='test-wml-flow', Key='DATA_3506-CX_-001.csv')['Body'])\n",
    "#data = pd.read_csv(r'D:\\Alpha Com\\New Platform\\TEST_WML_FLOW\\DATA_3506-CX_-001.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_data(data,name):\n",
    "    training_data = data\n",
    "    model_name = name\n",
    "    cos.put_object(Body=training_data.to_csv(encoding='utf-8', index=False), Bucket='training-model-data', Key=model_name+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "package_table = cos.get_object(Bucket='test-wml-flow', Key='PACKAGES.csv')['Body']\n",
    "package = pd.read_csv(package_table)\n",
    "\n",
    "component_table = cos.get_object(Bucket='test-wml-flow', Key='COMPONENT.csv')['Body']\n",
    "component = pd.read_csv(component_table)\n",
    "\n",
    "master_table = cos.get_object(Bucket='test-wml-flow', Key='MASTER_TABLE.csv')['Body']\n",
    "mastertable = pd.read_csv(master_table)\n",
    "\n",
    "model_table = cos.get_object(Bucket='test-wml-flow', Key='MODEL.csv')['Body']\n",
    "model = pd.read_csv(model_table)\n",
    "\n",
    "derive_table = cos.get_object(Bucket='test-wml-flow', Key='DERIVE_TARGET.csv')['Body']\n",
    "derive = pd.read_csv(derive_table)\n",
    "\n",
    "training_table = cos.get_object(Bucket='test-wml-flow', Key='TRAINING_DATA_LIST.csv')['Body']\n",
    "training = pd.read_csv(training_table)\n",
    "\n",
    "def upload_data(data,name):\n",
    "    training_data = data\n",
    "    model_name = name\n",
    "    cos.put_object(Body=training_data.to_csv(encoding='utf-8', index=False), Bucket='training-model-data', Key=model_name+'.csv')\n",
    "\n",
    "def data_for_training(inputpackage):\n",
    "    package_name = inputpackage\n",
    "    df1 = package[package['PACKAGE_NAME']==package_name]\n",
    "    package_id = df1['PACKAGE_ID'].iloc[0]\n",
    "\n",
    "    df2 = component[component['PACKAGE_ID']==package_id]\n",
    "    component_list = df2['COMPONENT_ID'].values\n",
    "\n",
    "    cols = ['OPC_CREATED_DT']\n",
    "    data_timestamp = data[cols]  \n",
    "\n",
    "    model_input = model\n",
    "    #model_input['INPUT_TRAINING_NAME'] = ''\n",
    "\n",
    "   \n",
    "    for i in component_list:\n",
    "        component_id = i\n",
    "        df3 = component[component['COMPONENT_ID']==component_id]\n",
    "        component_name = str(df3['COMPONENT_NAME'].iloc[0])\n",
    "\n",
    "        df4 = model[model['COMPONENT_ID'] == component_id]\n",
    "        model_list = df4['MODEL_ID'].values\n",
    "        derive_list = derive['MODEL_ID'].values\n",
    "            \n",
    "        for model_id in model_list:\n",
    "            #model_id_loc = int(model_id)-1\n",
    "            model_name = package_name+'_'+component_name+'_'+str(model_id)\n",
    "            print(model_id, model_name)\n",
    "\n",
    "            df5 = mastertable[mastertable['MODEL_ID'] == model_id]\n",
    "            target = df5[df5['TYPE'] =='TARGET']\n",
    "            predictor = df5[df5['TYPE'] =='PREDICTOR']\n",
    "           \n",
    "            targetlist = list(target['SENSOR_ID'].values)\n",
    "            predictorlist = list(predictor['SENSOR_ID'].values)\n",
    "            date = list(['OPC_CREATED_DT'])\n",
    "            cols = date + predictorlist + targetlist\n",
    "            print(cols)\n",
    "            training_data = data[cols]\n",
    "            #print(training_data.info())\n",
    "\n",
    "            #check if \n",
    "            if model_id in derive_list:\n",
    "                df6 = derive[derive['MODEL_ID']==model_id]\n",
    "                cal = df6['CALCULATE'].values\n",
    "            \n",
    "                if cal == 'AVG':\n",
    "                    training_data['sum_num'] = 0\n",
    "                    derivename = 'AVG'\n",
    "                    for n in targetlist:\n",
    "                        n = n.replace(\"PTTGSP.GSP5.3506.3506CX01_SALES GAS COMP.\", \"\")\n",
    "                        derivename = derivename+'_'+n\n",
    "                    for i in targetlist:\n",
    "                        training_data['sum_num'] = training_data['sum_num'] + training_data[i]   \n",
    "\n",
    "                    training_data[derivename] = training_data['sum_num']/len(targetlist)\n",
    "                    cols_drop = list(['sum_num']) + list(targetlist)\n",
    "                    training_data = training_data.drop(columns=cols_drop)\n",
    "                    training_data.info()\n",
    "                    upload_data(training_data,model_name)\n",
    "                    model_input.loc[(model_input.MODEL_ID == model_id ),'INPUT_TRAINING_NAME'] = model_name\n",
    "                    print(derivename)\n",
    "                    print('-------------------------AVG----------------------------')\n",
    "                \n",
    "                if cal == 'DIFF':\n",
    "                    training_data['diff_num'] = 0\n",
    "                    derivename = 'DIFF'\n",
    "                    for n in targetlist:\n",
    "                        n = n.replace(\"PTTGSP.GSP5.3506.3506CX01_SALES GAS COMP.\", \"\")\n",
    "                        derivename = derivename+'_'+n\n",
    "                    for i in targetlist:\n",
    "                        training_data['diff_num'] = training_data[i] - training_data['diff_num']\n",
    "\n",
    "                    training_data[derivename] = training_data['diff_num'].abs()\n",
    "                    cols_drop = list(['diff_num']) + list(targetlist)\n",
    "                    training_data = training_data.drop(columns=cols_drop)\n",
    "                    training_data.info()\n",
    "                    upload_data(training_data,model_name)\n",
    "                    model_input.loc[(model_input.MODEL_ID == model_id ),'INPUT_TRAINING_NAME']= model_name\n",
    "                    print(derivename)\n",
    "                    print('-------------------------DIFF----------------------------')\n",
    "\n",
    "            #if no derive column\n",
    "            else:\n",
    "                training_data.info()\n",
    "                upload_data(training_data,model_name)\n",
    "                model_input.loc[(model_input.MODEL_ID == model_id ),'INPUT_TRAINING_NAME']= model_name\n",
    "                print('-------------------------NORMAL----------------------------')\n",
    "        \n",
    "    print(model_input)\n",
    "    cos.put_object(Body=model_input.to_csv(encoding='utf-8', index=False), Bucket='test-wml-flow', Key='MODEL'+'.csv')\n",
    "\n",
    "           \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_for_training('3506-CX-001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('prepare training input data for each model')"
   ]
  }
 ]
}